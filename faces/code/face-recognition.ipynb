{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Using mlrun with OpenCV And PyTorch\n",
    " A complete pipeline of data processing, model training and serving function deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACTS_PATH = '/User/demos/demos/faces/artifacts/'\n",
    "CODE_PATH = '/User/demos/demos/faces/code/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and define mlrun functions for the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "from mlrun import new_function, code_to_function, NewTask, mount_v3io\n",
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-05-13 14:01:00,293 function spec saved to path: /User/demos/demos/faces/code/encode.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fea69ea66a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_fn = code_to_function('encode-images', image='yjbds/mlrun-horovod-gpu:0.4.5', kind='job', filename=CODE_PATH + 'encode.py')\n",
    "encode_fn.export(CODE_PATH + 'encode.yaml')\n",
    "encode_fn.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-05-13 14:01:00,827 function spec saved to path: /User/demos/demos/faces/code/train.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fea69ea6ac8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    train_fn = new_function(name='train', image='yjbds/mlrun-horovod-gpu:0.4.5', kind='mpijob', command=CODE_PATH + 'horovod_train.py')\n",
    "    train_fn.gpus(1)\n",
    "\n",
    "else:\n",
    "    train_fn = new_function(name='train', image='yjbds/mlrun-horovod-gpu:0.4.5', kind='job', command=CODE_PATH + 'train.py') \n",
    "\n",
    "train_fn.export(CODE_PATH + 'train.yaml')\n",
    "train_fn.spec.replicas = 2\n",
    "train_fn.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7fea71b120f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_serving_function = code_to_function(\n",
    "    name='recognize-faces', \n",
    "    filename='./nuclio-face-prediction.ipynb',\n",
    "    kind='nuclio')\n",
    "\n",
    "model_serving_function.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7fea69ea6860>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_serving_function = code_to_function(\n",
    "    name='video-api-server', \n",
    "    filename='./nuclio-api-serving.ipynb',\n",
    "    kind='nuclio')\n",
    "\n",
    "api_serving_function.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mlconf\n",
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='face recognition pipeline',\n",
    "    description='Creates and deploys a face recognition model'\n",
    ")\n",
    "def face_recognition_pipeline(with_cuda=False, with_horovod=False):\n",
    "    \n",
    "    encode = encode_fn.as_step(name='encode-images', handler='encode_images', artifact_path=ARTIFACTS_PATH, outputs=['idx2name', 'encodings_path'],\n",
    "                       inputs={'cuda': with_cuda})\n",
    "    \n",
    "    train = train_fn.as_step(name='train', artifact_path=ARTIFACTS_PATH, outputs=['model'], \n",
    "                               inputs={'processed_data': encode.outputs['encodings_path']})\n",
    "    \n",
    "    deploy_model = model_serving_function.deploy_step(project='default', models={'face_rec_v1': train.outputs['model']})\n",
    "    \n",
    "    deploy_api = api_serving_function.deploy_step(project='default').after(deploy_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace='default-tenant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For debug purposes compile pipeline code\n",
    "kfp.compiler.Compiler().compile(face_recognition_pipeline, 'face_rec.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.dev39.lab.iguazeng.com/pipelines/#/experiments/details/9e269769-2187-4eab-9901-37d0d9fd039d\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.dev39.lab.iguazeng.com/pipelines/#/runs/details/ffffc751-ea93-401f-9a75-fa26733c55cc\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arguments = {}\n",
    "run_result = client.create_run_from_pipeline_func(face_recognition_pipeline, arguments=arguments, run_name='face_rec_1', experiment_name='face_rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
